Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-l and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.











































Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74289/74289 [01:26<00:00, 863.22 examples/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                  | 0/820 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))69s/it]
Validation Report:
              precision    recall  f1-score   support
          -1       0.00      0.00      0.00       100
           0       0.00      0.00      0.00      6942
           1       0.43      1.00      0.60     31809
           2       0.17      0.00      0.00     16858
           3       0.00      0.00      0.00     15747
           4       0.00      0.00      0.00      2833
    accuracy                           0.43     74289
   macro avg       0.10      0.17      0.10     74289
weighted avg       0.22      0.43      0.26     74289
Confusion Matrix:
[[    0     0   100     0     0     0]
 [    0     0  6921    21     0     0]
 [    0     0 31701   108     0     0]
 [    0     0 16831    27     0     0]
 [    0     0 15744     3     0     0]
 [    0     0  2833     0     0     0]]
{'eval_loss': 4.3402791023254395, 'eval_precision': 0.09957532534634465, 'eval_recall': 0.166367724664397, 'eval_f1_macro': 0.10027496317331257, 'eval_accuracy': 0.42708880184145703, 'eval_runtime': 111.4952, 'eval_samples_per_second': 666.297, 'eval_steps_per_second': 0.045, 'epoch': 0}
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
  0%|                                                  | 0/820 [01:51<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
Traceback (most recent call last):
  File "/home/edward/Sila/train_edu_bert.py", line 196, in <module>
    main(args)
  File "/home/edward/Sila/train_edu_bert.py", line 150, in main
    trainer.train()
  File "/opt/conda/lib/python3.10/site-packages/transformers/trainer.py", line 1929, in train
    return inner_training_loop(
  File "/opt/conda/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/conda/lib/python3.10/site-packages/transformers/trainer.py", line 3349, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 2187, in backward
    if self.distributed_type == DistributedType.DEEPSPEED:
  File "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py", line 542, in distributed_type
    @property
KeyboardInterrupt